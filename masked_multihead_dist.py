"""
–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π TorchDistributionWrapper –¥–ª—è –ª—é–±—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ –¥–µ–π—Å—Ç–≤–∏–π
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∞–¥–∞–ø—Ç–∏—Ä—É–µ—Ç—Å—è –∫ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ actions_dict
"""

import numpy as np
import torch
from torch.distributions import Categorical, Normal, Bernoulli
from ray.rllib.models.torch.torch_action_dist import TorchDistributionWrapper
from ray.rllib.models import ModelCatalog
from typing import Dict, List, Any, Union, Optional
import math

class UniversalActionDistribution(TorchDistributionWrapper):
    """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –¥–∏—Å—Ç—Ä–∏–±—É—Ü–∏—è –¥–ª—è –ª—é–±—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ –¥–µ–π—Å—Ç–≤–∏–π"""
    
    def __init__(self, inputs, model):
        super().__init__(inputs, model)
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—é –¥–µ–π—Å—Ç–≤–∏–π –∏–∑ –º–æ–¥–µ–ª–∏
        if hasattr(model, 'get_action_spec'):
            self.action_spec = model.get_action_spec()
        else:
            # Fallback –Ω–∞ –¥–µ—Ñ–æ–ª—Ç
            self.action_spec = {
                "discrete_actions": {"target": 6},
                "continuous_actions": {"move": 3, "aim": 3},
                "binary_actions": {"fire": 1}
            }
        
        print(f"üéØ Universal Action Distribution initialized with spec: {self.action_spec}")
        
        # –ü–∞—Ä—Å–∏–º –≤—Ö–æ–¥—ã —Å–æ–≥–ª–∞—Å–Ω–æ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏
        self.parsed_inputs = self._parse_inputs(inputs)
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Å—Ç—Ä–∏–±—É—Ü–∏–∏
        self.discrete_dists = {}
        self.continuous_dists = {}
        self.binary_dists = {}
        
        self._create_distributions()
        
        # –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å RLLib
        self.dist = list(self.discrete_dists.values())[0] if self.discrete_dists else None
        self.last_sample = None

    def _parse_inputs(self, inputs: torch.Tensor) -> Dict[str, torch.Tensor]:
        """–ü–∞—Ä—Å–∏—Ç –ø–ª–æ—Å–∫–∏–π –≤—Ö–æ–¥–Ω–æ–π —Ç–µ–Ω–∑–æ—Ä —Å–æ–≥–ª–∞—Å–Ω–æ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏ –¥–µ–π—Å—Ç–≤–∏–π"""
        parsed = {}
        idx = 0
        
        # –î–∏—Å–∫—Ä–µ—Ç–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è
        for name, n_classes in self.action_spec["discrete_actions"].items():
            parsed[f"{name}_logits"] = inputs[..., idx:idx+n_classes]
            idx += n_classes
        
        # –ù–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è (mu + log_std)
        for name, action_dim in self.action_spec["continuous_actions"].items():
            parsed[f"{name}_mu"] = inputs[..., idx:idx+action_dim]
            idx += action_dim
            parsed[f"{name}_log_std"] = inputs[..., idx:idx+action_dim]
            idx += action_dim
        
        # –ë–∏–Ω–∞—Ä–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è
        for name, _ in self.action_spec["binary_actions"].items():
            parsed[f"{name}_logit"] = inputs[..., idx:idx+1]
            idx += 1
        
        return parsed

    def _create_distributions(self):
        """–°–æ–∑–¥–∞–µ—Ç –¥–∏—Å—Ç—Ä–∏–±—É—Ü–∏–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞ –¥–µ–π—Å—Ç–≤–∏–π"""
        
        # –î–∏—Å–∫—Ä–µ—Ç–Ω—ã–µ –¥–∏—Å—Ç—Ä–∏–±—É—Ü–∏–∏
        for name in self.action_spec["discrete_actions"]:
            logits_key = f"{name}_logits"
            if logits_key in self.parsed_inputs:
                self.discrete_dists[name] = Categorical(logits=self.parsed_inputs[logits_key])
        
        # –ù–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–µ –¥–∏—Å—Ç—Ä–∏–±—É—Ü–∏–∏
        for name in self.action_spec["continuous_actions"]:
            mu_key = f"{name}_mu"
            std_key = f"{name}_log_std"
            if mu_key in self.parsed_inputs and std_key in self.parsed_inputs:
                mu = self.parsed_inputs[mu_key]
                log_std = self.parsed_inputs[std_key]
                std = log_std.exp()
                self.continuous_dists[name] = Normal(mu, std)
        
        # –ë–∏–Ω–∞—Ä–Ω—ã–µ –¥–∏—Å—Ç—Ä–∏–±—É—Ü–∏–∏
        for name in self.action_spec["binary_actions"]:
            logit_key = f"{name}_logit"
            if logit_key in self.parsed_inputs:
                self.binary_dists[name] = Bernoulli(logits=self.parsed_inputs[logit_key])

    @staticmethod
    def required_model_output_shape(action_space, model_config):
        """–í—ã—á–∏—Å–ª—è–µ–º —Ç—Ä–µ–±—É–µ–º—ã–π —Ä–∞–∑–º–µ—Ä –≤—ã—Ö–æ–¥–∞ –º–æ–¥–µ–ª–∏"""
        
        # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞ –º–æ–¥–µ–ª–∏
        custom_config = model_config.get("custom_model_config", {})
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å —è–≤–Ω–∞—è —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è –¥–µ–π—Å—Ç–≤–∏–π
        if "action_spec" in custom_config:
            spec = custom_config["action_spec"]
            total = 0
            total += sum(spec.get("discrete_actions", {}).values())
            total += sum(v * 2 for v in spec.get("continuous_actions", {}).values())  # *2 –¥–ª—è mu + log_std
            total += len(spec.get("binary_actions", {}))
            return total
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º action_space
        if hasattr(action_space, 'spaces'):
            total = 0
            for name, space in action_space.spaces.items():
                if hasattr(space, 'n'):
                    # Discrete
                    total += space.n
                elif hasattr(space, 'shape'):
                    # Continuous
                    action_dim = space.shape[0] if space.shape else 1
                    if name in ["fire", "shoot", "attack"] or action_dim == 1:
                        total += 1  # Binary
                    else:
                        total += action_dim * 2  # mu + log_std
            return total
        
        # Fallback –Ω–∞ –¥–µ—Ñ–æ–ª—Ç (3D –≤–µ—Ä—Å–∏—è)
        max_enemies = custom_config.get("max_enemies", 6)
        return max_enemies + 3*2 + 3*2 + 1  # target + move(mu+std) + aim(mu+std) + fire

    def _convert_to_numpy_dict(self, tensor_dict: Dict[str, torch.Tensor], squeeze_batch: bool = False) -> Union[Dict[str, np.ndarray], Dict[str, Union[int, float, np.ndarray]]]:
        """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Ç–µ–Ω–∑–æ—Ä—ã –≤ numpy dict –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞"""
        result = {}
        
        for name, tensor in tensor_dict.items():
            if tensor.is_cuda:
                tensor = tensor.cpu()
            
            numpy_val = tensor.numpy()
            
            if squeeze_batch and numpy_val.ndim > 0:
                numpy_val = numpy_val[0] if numpy_val.shape[0] == 1 else numpy_val
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º scalar arrays –≤ Python —Ç–∏–ø—ã
            if numpy_val.ndim == 0:
                result[name] = numpy_val.item()
            elif numpy_val.shape == (1,):
                result[name] = numpy_val[0]
            else:
                result[name] = numpy_val
        
        return result

    def _sample_all_actions(self, deterministic: bool = False) -> Dict[str, torch.Tensor]:
        """–°—ç–º–ø–ª–∏—Ä—É–µ—Ç –≤—Å–µ –¥–µ–π—Å—Ç–≤–∏—è"""
        sampled = {}
        
        # –î–∏—Å–∫—Ä–µ—Ç–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è
        for name, dist in self.discrete_dists.items():
            if deterministic:
                sampled[name] = torch.argmax(dist.logits, dim=-1)
            else:
                sampled[name] = dist.sample()
        
        # –ù–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è
        for name, dist in self.continuous_dists.items():
            if deterministic:
                sampled[name] = torch.tanh(dist.loc)  # mean
            else:
                sampled[name] = torch.tanh(dist.rsample())  # —Å –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞–º–∏
        
        # –ë–∏–Ω–∞—Ä–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è
        for name, dist in self.binary_dists.items():
            if deterministic:
                sampled[name] = (dist.logits > 0).long()
            else:
                sampled[name] = dist.sample().long()
        
        return sampled

    def sample(self):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—ç–º–ø–ª –≤ —Ñ–æ—Ä–º–∞—Ç–µ Dict —Å numpy arrays"""
        sampled_dict = self._sample_all_actions(deterministic=False)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        self.last_sample = sampled_dict
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ numpy dict
        batch_size = next(iter(sampled_dict.values())).size(0)
        squeeze_batch = batch_size == 1
        
        return self._convert_to_numpy_dict(sampled_dict, squeeze_batch)

    def deterministic_sample(self):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å—ç–º–ø–ª"""
        sampled_dict = self._sample_all_actions(deterministic=True)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        self.last_sample = sampled_dict
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ numpy dict
        batch_size = next(iter(sampled_dict.values())).size(0)
        squeeze_batch = batch_size == 1
        
        return self._convert_to_numpy_dict(sampled_dict, squeeze_batch)

    def logp(self, x):
        """–í—ã—á–∏—Å–ª—è–µ–º log probability –¥–ª—è —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π"""
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Ç–µ–Ω–∑–æ—Ä—ã –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if isinstance(x, dict):
            action_tensors = {}
            device = next(iter(self.parsed_inputs.values())).device
            
            for name, value in x.items():
                if isinstance(value, np.ndarray):
                    action_tensors[name] = torch.from_numpy(value).to(device)
                elif isinstance(value, (int, float)):
                    action_tensors[name] = torch.tensor(value, device=device)
                elif isinstance(value, torch.Tensor):
                    action_tensors[name] = value.to(device)
                else:
                    action_tensors[name] = torch.tensor(value, device=device)
        else:
            # –ï—Å–ª–∏ x - –ø–ª–æ—Å–∫–∏–π —Ç–µ–Ω–∑–æ—Ä, –Ω—É–∂–Ω–æ –µ–≥–æ —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –æ–±—Ä–∞—Ç–Ω–æ
            # –≠—Ç–æ —Å–ª–æ–∂–Ω–µ–µ, –ø–æ—ç—Ç–æ–º—É –ª—É—á—à–µ —Ä–∞–±–æ—Ç–∞—Ç—å —Å dict —Ñ–æ—Ä–º–∞—Ç–æ–º
            raise ValueError("logp expects dict format for universal actions")
        
        total_logp = 0.0
        batch_size = None
        
        # –î–∏—Å–∫—Ä–µ—Ç–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è
        for name, dist in self.discrete_dists.items():
            if name in action_tensors:
                action = action_tensors[name]
                if action.dim() == 0:
                    action = action.unsqueeze(0)
                if batch_size is None:
                    batch_size = action.size(0)
                total_logp = total_logp + dist.log_prob(action.long())
        
        # –ù–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è
        for name, dist in self.continuous_dists.items():
            if name in action_tensors:
                action = action_tensors[name]
                if action.dim() == 1 and action.size(0) != batch_size:
                    action = action.unsqueeze(0)
                
                # Inverse tanh –¥–ª—è –¥–µ–π—Å—Ç–≤–∏–π –≤ [-1, 1]
                eps = 1e-6
                action_clamped = torch.clamp(action, -1+eps, 1-eps)
                z = 0.5 * (torch.log1p(action_clamped) - torch.log1p(-action_clamped))
                
                logp_gaussian = dist.log_prob(z).sum(-1)
                logp_tanh_correction = -torch.log(1 - action_clamped.pow(2) + eps).sum(-1)
                
                total_logp = total_logp + logp_gaussian + logp_tanh_correction
        
        # –ë–∏–Ω–∞—Ä–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è
        for name, dist in self.binary_dists.items():
            if name in action_tensors:
                action = action_tensors[name]
                if action.dim() == 0:
                    action = action.unsqueeze(0)
                if action.dim() == 2 and action.size(1) == 1:
                    action = action.squeeze(-1)
                
                p = torch.sigmoid(dist.logits.squeeze(-1))
                logp_binary = torch.where(
                    action > 0.5, 
                    torch.log(p + eps), 
                    torch.log(1 - p + eps)
                )
                total_logp = total_logp + logp_binary
        
        # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏–º–µ–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—É—é —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å
        if isinstance(total_logp, (int, float)):
            if batch_size is not None:
                total_logp = torch.full((batch_size,), total_logp, 
                                     device=next(iter(self.parsed_inputs.values())).device)
            else:
                total_logp = torch.tensor(total_logp)
        
        return total_logp

    def sampled_action_logp(self):
        """–ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º –º–µ—Ç–æ–¥ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Ä–∞–±–æ—Ç—ã —Å last_sample"""
        if self.last_sample is None:
            self.sample()
        return self.logp(self.last_sample)

    def kl(self, other):
        """–†–µ–∞–ª–∏–∑—É–µ–º KL divergence"""
        if not isinstance(other, UniversalActionDistribution):
            # –ï—Å–ª–∏ –¥—Ä—É–≥–∞—è –¥–∏—Å—Ç—Ä–∏–±—É—Ü–∏—è –Ω–µ —Ç–æ–≥–æ –∂–µ —Ç–∏–ø–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º 0
            batch_size = next(iter(self.parsed_inputs.values())).size(0)
            return torch.zeros(batch_size, device=next(iter(self.parsed_inputs.values())).device)
        
        total_kl = 0.0
        
        # KL –¥–ª—è –¥–∏—Å–∫—Ä–µ—Ç–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π
        for name in self.discrete_dists:
            if name in other.discrete_dists:
                kl_discrete = torch.distributions.kl.kl_divergence(
                    self.discrete_dists[name], other.discrete_dists[name]
                )
                total_kl = total_kl + kl_discrete
        
        # KL –¥–ª—è –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π
        for name in self.continuous_dists:
            if name in other.continuous_dists:
                kl_continuous = torch.distributions.kl.kl_divergence(
                    self.continuous_dists[name], other.continuous_dists[name]
                ).sum(-1)
                total_kl = total_kl + kl_continuous
        
        # KL –¥–ª—è –±–∏–Ω–∞—Ä–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π
        for name in self.binary_dists:
            if name in other.binary_dists:
                kl_binary = torch.distributions.kl.kl_divergence(
                    self.binary_dists[name], other.binary_dists[name]
                ).squeeze(-1)
                total_kl = total_kl + kl_binary
        
        return total_kl

    def entropy(self):
        """–í—ã—á–∏—Å–ª—è–µ–º —ç–Ω—Ç—Ä–æ–ø–∏—é –¥–ª—è –≤—Å–µ—Ö –¥–µ–π—Å—Ç–≤–∏–π"""
        total_entropy = 0.0
        
        # –≠–Ω—Ç—Ä–æ–ø–∏—è –¥–∏—Å–∫—Ä–µ—Ç–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π
        for dist in self.discrete_dists.values():
            total_entropy = total_entropy + dist.entropy()
        
        # –≠–Ω—Ç—Ä–æ–ø–∏—è –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π
        for dist in self.continuous_dists.values():
            total_entropy = total_entropy + dist.entropy().sum(-1)
        
        # –≠–Ω—Ç—Ä–æ–ø–∏—è –±–∏–Ω–∞—Ä–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π
        for dist in self.binary_dists.values():
            p = torch.sigmoid(dist.logits.squeeze(-1))
            binary_entropy = -(p*torch.log(p+1e-8) + (1-p)*torch.log(1-p+1e-8))
            total_entropy = total_entropy + binary_entropy
        
        return total_entropy

    def get_action_breakdown(self) -> Dict[str, Any]:
        """–£—Ç–∏–ª–∏—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–µ–π—Å—Ç–≤–∏–π (–¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)"""
        return {
            "action_spec": self.action_spec,
            "discrete_actions": list(self.discrete_dists.keys()),
            "continuous_actions": list(self.continuous_dists.keys()),
            "binary_actions": list(self.binary_dists.keys()),
            "total_distributions": len(self.discrete_dists) + len(self.continuous_dists) + len(self.binary_dists)
        }


# –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∏—Å—Ç—Ä–∏–±—É—Ü–∏–∏ –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
class MaskedTargetMoveAimFire3D(UniversalActionDistribution):
    """3D –≤–µ—Ä—Å–∏—è –¥–ª—è target + move + aim + fire (–æ–±—Ä–∞—Ç–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å)"""
    
    def __init__(self, inputs, model):
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—É—é —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—é –¥–ª—è 3D
        self.action_spec = {
            "discrete_actions": {"target": getattr(model, 'max_enemies', 6)},
            "continuous_actions": {"move": 3, "aim": 3},  # 3D
            "binary_actions": {"fire": 1}
        }
        super().__init__(inputs, model)

class MaskedTargetMoveAimFire(UniversalActionDistribution):
    """2D –≤–µ—Ä—Å–∏—è –¥–ª—è target + move + aim + fire (–æ–±—Ä–∞—Ç–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å)"""
    
    def __init__(self, inputs, model):
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—É—é —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—é –¥–ª—è 2D
        self.action_spec = {
            "discrete_actions": {"target": getattr(model, 'max_enemies', 6)},
            "continuous_actions": {"move": 2, "aim": 2},  # 2D
            "binary_actions": {"fire": 1}
        }
        super().__init__(inputs, model)


def create_adaptive_action_distribution(inputs, model):
    """
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ–∑–¥–∞–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â—É—é –¥–∏—Å—Ç—Ä–∏–±—É—Ü–∏—é –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–æ–¥–µ–ª–∏
    """
    
    # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—é –∏–∑ –º–æ–¥–µ–ª–∏
    if hasattr(model, 'get_action_spec'):
        return UniversalActionDistribution(inputs, model)
    
    # Fallback - –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∞–∑–º–µ—Ä –≤—Ö–æ–¥–∞
    input_size = inputs.shape[-1]
    max_enemies = getattr(model, 'max_enemies', 6)
    
    # –í—ã—á–∏—Å–ª—è–µ–º –æ–∂–∏–¥–∞–µ–º—ã–µ —Ä–∞–∑–º–µ—Ä—ã
    size_2d = max_enemies + 2*2 + 2*2 + 1  # target + move_2d + aim_2d + fire
    size_3d = max_enemies + 3*2 + 3*2 + 1  # target + move_3d + aim_3d + fire
    
    if input_size >= size_3d:
        print(f"üéØ Auto-detected 3D action space (size={input_size})")
        return MaskedTargetMoveAimFire3D(inputs, model)
    else:
        print(f"üéØ Auto-detected 2D action space (size={input_size})")
        return MaskedTargetMoveAimFire(inputs, model)


# –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –¥–∏—Å—Ç—Ä–∏–±—É—Ü–∏–∏
ModelCatalog.register_custom_action_dist("universal_action_dist", UniversalActionDistribution)
ModelCatalog.register_custom_action_dist("masked_multihead", MaskedTargetMoveAimFire)
ModelCatalog.register_custom_action_dist("masked_multihead_3d", MaskedTargetMoveAimFire3D)
ModelCatalog.register_custom_action_dist("masked_multihead_adaptive", create_adaptive_action_distribution)


# –£—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–º–∏ –¥–µ–π—Å—Ç–≤–∏—è–º–∏
class ActionSpecAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏ –¥–µ–π—Å—Ç–≤–∏–π"""
    
    @staticmethod
    def analyze_action_space(action_space) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç action_space –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—é"""
        spec = {
            "discrete_actions": {},
            "continuous_actions": {},
            "binary_actions": {},
            "total_output_size": 0
        }
        
        if hasattr(action_space, 'spaces'):
            for name, space in action_space.spaces.items():
                if hasattr(space, 'n'):
                    # Discrete space
                    spec["discrete_actions"][name] = space.n
                    spec["total_output_size"] += space.n
                elif hasattr(space, 'shape'):
                    # Continuous space
                    action_dim = space.shape[0] if space.shape else 1
                    if action_dim == 1 and name in ["fire", "shoot", "attack", "use"]:
                        spec["binary_actions"][name] = 1
                        spec["total_output_size"] += 1
                    else:
                        spec["continuous_actions"][name] = action_dim
                        spec["total_output_size"] += action_dim * 2  # mu + log_std
        
        return spec
    
    @staticmethod
    def print_action_analysis(action_space, model_config=None):
        """–ü–µ—á–∞—Ç–∞–µ—Ç –∞–Ω–∞–ª–∏–∑ action_space –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏"""
        spec = ActionSpecAnalyzer.analyze_action_space(action_space)
        
        print("üîç Action Space Analysis:")
        print(f"   Discrete actions: {spec['discrete_actions']}")
        print(f"   Continuous actions: {spec['continuous_actions']}")
        print(f"   Binary actions: {spec['binary_actions']}")
        print(f"   Total output size needed: {spec['total_output_size']}")
        
        if model_config:
            custom_config = model_config.get("custom_model_config", {})
            if "max_enemies" in custom_config:
                print(f"   Max enemies from config: {custom_config['max_enemies']}")
        
        return spec


def test_universal_action_distribution():
    """–¢–µ—Å—Ç —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã –¥–µ–π—Å—Ç–≤–∏–π"""
    print("üß™ Testing Universal Action Distribution...")
    
    # –°–æ–∑–¥–∞–µ–º –º–æ–∫ –º–æ–¥–µ–ª—å
    class MockModel:
        def __init__(self, action_spec):
            self._action_spec = action_spec
            self.max_enemies = action_spec["discrete_actions"].get("target", 6)
        
        def get_action_spec(self):
            return self._action_spec
    
    # –¢–µ—Å—Ç 1: –ë–∞–∑–æ–≤–∞—è 3D –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    action_spec_3d = {
        "discrete_actions": {"target": 4},
        "continuous_actions": {"move": 3, "aim": 3},
        "binary_actions": {"fire": 1}
    }
    
    model_3d = MockModel(action_spec_3d)
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –≤—Ö–æ–¥—ã
    batch_size = 2
    total_size = 4 + 3*2 + 3*2 + 1  # target + move(mu+std) + aim(mu+std) + fire
    test_inputs = torch.randn(batch_size, total_size)
    
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Å—Ç—Ä–∏–±—É—Ü–∏—é
    dist_3d = UniversalActionDistribution(test_inputs, model_3d)
    
    print(f"‚úÖ 3D Distribution created:")
    print(f"   Action breakdown: {dist_3d.get_action_breakdown()}")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å–µ–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ
    sample = dist_3d.sample()
    print(f"   Sample keys: {list(sample.keys())}")
    print(f"   Sample types: {[(k, type(v)) for k, v in sample.items()]}")
    
    # –¢–µ—Å—Ç 2: –ö–∞—Å—Ç–æ–º–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    custom_spec = {
        "discrete_actions": {"weapon": 3, "formation": 5},
        "continuous_actions": {"velocity": 2, "direction": 1},
        "binary_actions": {"shield": 1, "boost": 1}
    }
    
    model_custom = MockModel(custom_spec)
    custom_size = 3 + 5 + 2*2 + 1*2 + 1 + 1  # weapon + formation + vel(mu+std) + dir(mu+std) + shield + boost
    test_inputs_custom = torch.randn(batch_size, custom_size)
    
    dist_custom = UniversalActionDistribution(test_inputs_custom, model_custom)
    sample_custom = dist_custom.sample()
    
    print(f"‚úÖ Custom Distribution created:")
    print(f"   Action breakdown: {dist_custom.get_action_breakdown()}")
    print(f"   Sample keys: {list(sample_custom.keys())}")
    
    # –¢–µ—Å—Ç –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    logp = dist_custom.logp(sample_custom)
    print(f"   Log probability: {logp.shape}")
    
    print("‚úÖ Universal action distribution tests passed!")


if __name__ == "__main__":
    test_universal_action_distribution()